P8105 Homework 2
================
Kyung Suk Lee
2020-09-27

  - [Problem 1](#problem-1)
      - [1-1) Read and Clean Mr. Trash Wheel
        Sheet](#read-and-clean-mr.-trash-wheel-sheet)
      - [1-2) Read and Clean Precipitation Data
        (2017)](#read-and-clean-precipitation-data-2017)
      - [1-3) Read and Clean Precipitation Data
        (2018)](#read-and-clean-precipitation-data-2018)
      - [1-4) Combine Annual
        Precipitation](#combine-annual-precipitation)
  - [Problem 2](#problem-2)
      - [2-1) Read and Clean NYC Transit
        Data](#read-and-clean-nyc-transit-data)
      - [2-2) Reformat Data](#reformat-data)
  - [Problem 3](#problem-3)
      - [3-1) Clean Pols-month Data](#clean-pols-month-data)
      - [3-2) Clean Snp Data](#clean-snp-data)
      - [3-3) Tidy Unemployment Data](#tidy-unemployment-data)
      - [3-4) Join Datasets](#join-datasets)

``` r
library(tidyverse)
library(readxl)

knitr::opts_chunk$set(comment = NA, message = F, warning = F, echo = T)
```

## Problem 1

### 1-1) Read and Clean Mr. Trash Wheel Sheet

``` r
# Read excel file
# Specify the sheet (Mr. Trash Wheel)
# Omit non-data entries
# Use reasonable variable names
# Omit rows that do not include dumpster-specific data
# Round the number of sports balls
# Convert the result to integer

trashwheel_df = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
            sheet = "Mr. Trash Wheel", 
            range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
    )

trashwheel_df
```

    # A tibble: 344 x 14
       dumpster month  year date                weight_tons volume_cubic_ya~
          <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
     1        1 May    2014 2014-05-16 00:00:00        4.31               18
     2        2 May    2014 2014-05-16 00:00:00        2.74               13
     3        3 May    2014 2014-05-16 00:00:00        3.45               15
     4        4 May    2014 2014-05-17 00:00:00        3.1                15
     5        5 May    2014 2014-05-17 00:00:00        4.06               18
     6        6 May    2014 2014-05-20 00:00:00        2.71               13
     7        7 May    2014 2014-05-21 00:00:00        1.91                8
     8        8 May    2014 2014-05-28 00:00:00        3.7                16
     9        9 June   2014 2014-06-05 00:00:00        2.52               14
    10       10 June   2014 2014-06-11 00:00:00        3.76               18
    # ... with 334 more rows, and 8 more variables: plastic_bottles <dbl>,
    #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    #   homes_powered <dbl>

### 1-2) Read and Clean Precipitation Data (2017)

``` r
# Read excel
# Specify the sheet (2017 Precipitation)
# Omit Precipitation (in)
# Omit rows without precipitation data
# Add a variable year

precip_2017 = 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             sheet = "2017 Precipitation",
             skip = 1) %>%
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)

precip_2017
```

    # A tibble: 12 x 3
        year month total
       <dbl> <dbl> <dbl>
     1  2017     1  2.34
     2  2017     2  1.46
     3  2017     3  3.57
     4  2017     4  3.99
     5  2017     5  5.64
     6  2017     6  1.4 
     7  2017     7  7.09
     8  2017     8  4.44
     9  2017     9  1.95
    10  2017    10  0   
    11  2017    11  0.11
    12  2017    12  0.94

### 1-3) Read and Clean Precipitation Data (2018)

``` r
# Read excel
# Specify the sheet (2017 Precipitation)
# Omit Precipitation (in)
# Omit rows without precipitation data
# Add a variable year

precip_2018 = 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             sheet = "2018 Precipitation",
             skip = 1) %>%
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2018
```

    # A tibble: 12 x 3
        year month total
       <dbl> <dbl> <dbl>
     1  2018     1  0.94
     2  2018     2  4.8 
     3  2018     3  2.69
     4  2018     4  4.69
     5  2018     5  9.27
     6  2018     6  4.77
     7  2018     7 10.2 
     8  2018     8  6.45
     9  2018     9 10.5 
    10  2018    10  2.12
    11  2018    11  7.82
    12  2018    12  6.11

### 1-4) Combine Annual Precipitation

``` r
# Create month dataframe
# Combine precipitation 2017 & 2018
# Left join precipitation & month by month

month_df = 
  tibble(month = 1:12,
         month_name = month.name)

precip_df = 
  bind_rows(precip_2018, precip_2017)

combined_precip_df = 
  left_join(precip_df, month_df, by = "month") %>%
  relocate(year, month, month_name)

combined_precip_df
```

    # A tibble: 24 x 4
        year month month_name total
       <dbl> <dbl> <chr>      <dbl>
     1  2018     1 January     0.94
     2  2018     2 February    4.8 
     3  2018     3 March       2.69
     4  2018     4 April       4.69
     5  2018     5 May         9.27
     6  2018     6 June        4.77
     7  2018     7 July       10.2 
     8  2018     8 August      6.45
     9  2018     9 September  10.5 
    10  2018    10 October     2.12
    # ... with 14 more rows

  - Some description about the *Mr. Trashwheel Data*<br/> This dataset
    contains information regarding to the *Mr. Trashwheel* trash
    collector in Baltimore, Maryland. As trash enters the inner harbor,
    the trashwheel collects that trash, and stores it in a dumpster. The
    final dataset contains information on *dumpster, month, year, date,
    weight\_tons, volume\_cubic\_yards, plastic\_bottles, polystyrene,
    cigarette\_butts, glass\_bottles, grocery\_bags, chip\_bags,
    sports\_balls, homes\_powered*. There are total of **344** rows and
    **14** columns in the dataset. If we look at some key variables,
    from **2014-05-16** to **2019-06-17**, total of **1,122** tons of
    trash were gathered, averaging **3** tons during the observed
    period. Among various trash collected, the number of cigarette butts
    collected was the highest. On average, in 2014, **94,591**; in 2015,
    **40,225**; in 2016, **37,639**; in 2017, **12,709**; in 2018,
    **8,638**; in 2019, **4,651** cigarette butts were collected,
    respectively. From the average number of cigarette butts collected
    for each year, we could see a decreasing number of average of
    cigarette butts collected from year 2014 to 2019.<br/>

  - Some description about the *2017 & 2018 Precipitation Data*<br/>
    This dataset contains combined information of precipitation data
    from **2017** to **2018**. It comprises of **1** to **12** months
    period for each year, resulting total of **24** observations with
    *year, month, month\_name, total* columns. The total precipitation
    during the observed periods was **103** inches, averaging **4**
    inches. When we compare the average of total precipitation between
    2017 (**3** inches) and 2018 (**6** inches), we can see that the
    average of total precipitation in 2018 was higher. For available
    data,<br/>
    
      - The total precipitation in 2018 was **70**
      - The median number of sports balls in a dumpster in 2017 was
        **8**

-----

## Problem 2

### 2-1) Read and Clean NYC Transit Data

``` r
# Read and clean the data
# Retain variables
# Convert the entry variable

transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))

transit_df
```

    # A tibble: 1,868 x 19
       line  station_name station_latitude station_longitu~ route1 route2 route3
       <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
     1 4 Av~ 25th St                  40.7            -74.0 R      <NA>   <NA>  
     2 4 Av~ 25th St                  40.7            -74.0 R      <NA>   <NA>  
     3 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
     4 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
     5 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
     6 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
     7 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
     8 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
     9 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
    10 4 Av~ 53rd St                  40.6            -74.0 R      <NA>   <NA>  
    # ... with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    #   route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>,
    #   route11 <dbl>, entrance_type <chr>, entry <lgl>, vending <chr>, ada <lgl>

  - Some description about the *NYC Transit Data*<br/> This data
    contains information related to each entrance and exit for each
    subway station in NYC. This dataset is comprised of *line,
    station\_name, station\_latitude, station\_longitude, route1,
    route2, route3, route4, route5, route6, route7, route8, route9,
    route10, route11, entrance\_type, entry, vending, ada* columns. In
    terms of data cleaning steps so far, first I have replaced each
    spaces by underscore (stylized as snake\_case). Second, I have
    retained variables of interest. Third, I have recoded *entry*
    variable from character (YES Vs NO) values to a logical (True Vs
    False) values. The resulting dataset has the size of **1868** rows
    and **19** columns. The current dataset is **not tidy** enough for
    further analysis because it is difficult for us to analyze how other
    variables relates to *route1* to *route11*. Thus, it could be
    reformatted so that *route number* and *route name* become distinct
    variables which would be more convenient for analyzing the data.
    Regards to the questions,<br/>
      - There are **465** distinct stations identified by both name and
        line
      - There are **84** stations that are compliant with ADA
      - There are **183** station entrances / exits without vending.
        Among them, **69** allow entry, resulting, approximately,
        **38**% of station entrances / exits without vending to allow
        entrance

### 2-2) Reformat Data

``` r
# Make route number and route name distinct variables

transit_tidy_df =
  transit_df %>%
  gather(key = route_number, value = route_name, route1:route11)

transit_tidy_df
```

    # A tibble: 20,548 x 10
       line  station_name station_latitude station_longitu~ entrance_type entry
       <chr> <chr>                   <dbl>            <dbl> <chr>         <lgl>
     1 4 Av~ 25th St                  40.7            -74.0 Stair         TRUE 
     2 4 Av~ 25th St                  40.7            -74.0 Stair         TRUE 
     3 4 Av~ 36th St                  40.7            -74.0 Stair         TRUE 
     4 4 Av~ 36th St                  40.7            -74.0 Stair         TRUE 
     5 4 Av~ 36th St                  40.7            -74.0 Stair         TRUE 
     6 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
     7 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
     8 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
     9 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
    10 4 Av~ 53rd St                  40.6            -74.0 Stair         TRUE 
    # ... with 20,538 more rows, and 4 more variables: vending <chr>, ada <lgl>,
    #   route_number <chr>, route_name <chr>

  - Questions regarding to *reformatted data*<br/>
      - There are **60** distinct stations that serve the A train
      - Of the stations that serve the A train, there are **17**
        stations that are ADA compliant

-----

## Problem 3

### 3-1) Clean Pols-month Data

``` r
# Clean the data
# Separate 'mon' to year, month, and day
# Replace month number with month name
# Create a president variable
# Remove prez_dem, prez_gop, day variables

month_df1 = 
  tibble(month = 1:12,
         month_name = month.name)

polsmonth_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day"), sep = "-") %>%
  mutate(
    month = as.integer(month),
    year = as.integer(year)
    )

polsmonth_tidy_df =
  left_join(polsmonth_df, month_df1, by = "month") %>%
  select(-month) %>%
  relocate(year, month_name) %>%
  mutate(month_name = str_to_lower(month_name),
         president = ifelse(prez_gop !=0, "gop", "dem")
         ) %>%
  select(-prez_gop, -prez_dem, -day) %>%
  rename(month = month_name)

polsmonth_tidy_df
```

    # A tibble: 822 x 9
        year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
       <int> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
     1  1947 january        23      51     253      23      45     198 dem      
     2  1947 february       23      51     253      23      45     198 dem      
     3  1947 march          23      51     253      23      45     198 dem      
     4  1947 april          23      51     253      23      45     198 dem      
     5  1947 may            23      51     253      23      45     198 dem      
     6  1947 june           23      51     253      23      45     198 dem      
     7  1947 july           23      51     253      23      45     198 dem      
     8  1947 august         23      51     253      23      45     198 dem      
     9  1947 september      23      51     253      23      45     198 dem      
    10  1947 october        23      51     253      23      45     198 dem      
    # ... with 812 more rows

### 3-2) Clean Snp Data

``` r
# Clean the data
# Arrange according to year and month
# Organize leading columns

month_df2 = 
  tibble(month = 1:12,
         month_name = month.name)

snp_df =
  read_csv("./fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, c("month", "day", "year"), sep = "/") %>%
  mutate(
    month = as.integer(month),
    year = as.integer(year)
    )

snp_tidy_df =
  left_join(snp_df, month_df2, by = "month") %>%
  relocate(year, month_name) %>%
  mutate(month_name = str_to_lower(month_name)) %>%
  select(-month, -day) %>%
  rename(
    month = month_name,
    close_stock_index = close
    )

snp_tidy_df
```

    # A tibble: 787 x 3
        year month    close_stock_index
       <int> <chr>                <dbl>
     1  2015 july                 2080.
     2  2015 june                 2063.
     3  2015 may                  2107.
     4  2015 april                2086.
     5  2015 march                2068.
     6  2015 february             2104.
     7  2015 january              1995.
     8  2014 december             2059.
     9  2014 november             2068.
    10  2014 october              2018.
    # ... with 777 more rows

### 3-3) Tidy Unemployment Data

``` r
# Tidy the unemployment data
# Switch from “wide” to “long” format
# Ensure that key variables have the same name
# Ensure that key variables take the same values

unemployment_tidy_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  rename(
    january = "jan",
    feburary = "feb",
    march = "mar",
    april = "apr",
    may = "may",
    june = "jun",
    july = "jul",
    august = "aug",
    september = "sep",
    october = "oct",
    november = "nov",
    december ="dec"
    ) %>%
  pivot_longer(
    january:december,
    names_to = "month",
    values_to = "unemployment_rate"
    )

unemployment_tidy_df
```

    # A tibble: 816 x 3
        year month     unemployment_rate
       <dbl> <chr>                 <dbl>
     1  1948 january                 3.4
     2  1948 feburary                3.8
     3  1948 march                   4  
     4  1948 april                   3.9
     5  1948 may                     3.5
     6  1948 june                    3.6
     7  1948 july                    3.6
     8  1948 august                  3.9
     9  1948 september               3.8
    10  1948 october                 3.7
    # ... with 806 more rows

### 3-4) Join Datasets

``` r
# Join the datasets

joined_df = 
  left_join(polsmonth_tidy_df, snp_tidy_df, by = c("year", "month"))

final_df = 
  left_join(joined_df, unemployment_tidy_df, by = c("year", "month"))

final_df
```

    # A tibble: 822 x 11
        year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
       <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
     1  1947 janu~      23      51     253      23      45     198 dem      
     2  1947 febr~      23      51     253      23      45     198 dem      
     3  1947 march      23      51     253      23      45     198 dem      
     4  1947 april      23      51     253      23      45     198 dem      
     5  1947 may        23      51     253      23      45     198 dem      
     6  1947 june       23      51     253      23      45     198 dem      
     7  1947 july       23      51     253      23      45     198 dem      
     8  1947 augu~      23      51     253      23      45     198 dem      
     9  1947 sept~      23      51     253      23      45     198 dem      
    10  1947 octo~      23      51     253      23      45     198 dem      
    # ... with 812 more rows, and 2 more variables: close_stock_index <dbl>,
    #   unemployment_rate <dbl>

  - Some description of *pols-month* dataset<br/> This dataset contains
    information related to the number of national politicians who are
    democratic or republican during the years from **1947** to **2015**.
    This dataset is comprised of *year, month, gov\_gop, sen\_gop,
    rep\_gop, gov\_dem, sen\_dem, rep\_dem, president* columns and has
    the size of **822** rows and **9** columns. Among various variables,
    I have created new variable *president* indicating whether the
    president was democratic (dem) or republican (gop) on the associated
    date. During the observed years, there were **432** presidents who
    were republican and **390** presidents who were democratic. Thus, by
    comparing the two parties, we are able to notice that the candidates
    from republican party were more appointed as the president compared
    to the democratic party.<br/>

  - Some description of *snp* dataset<br/> This dataset contains
    information related to Standard & Poor’s stock market index (S\&P),
    often used as a representative measure of stock market as a whole
    during the years from **1950** to **2015**. This dataset is
    comprised of *year, month, close\_stock\_index* variables and has
    the size of **787** rows and **3** columns. When we look at the
    average closing values of the S\&P stock index on the associated
    date, the values are, approximately, **59** (from 1950 to 1970);
    **157** (from 1970 to 1990); **931** (from 1990 to 2010); **1,541**
    (from 2010 to 2015). Hence, we can see that S\&P stock index has
    increased over the years.<br/>

  - Some description of *unemployment* dataset<br/> This dataset
    contains information related to percentage of unemployment during
    the years from **1948** to **2015**. This dataset is comprised of
    *year, month, unemployment\_rate* variables and has the size of
    **816** rows and **3** columns. When we look at the average
    percentage of unemployment rate on the associated date, the values
    are, approximately, **5**% (from 1948 to 1970); **7**% (from 1970 to
    1990); **6**% (from 1990 to 2010); **8**% (from 2010 to 2015).
    Therefore, we can see that unemployment rate has experienced
    somewhat increasing trend over the years.<br/>
